"""
Enhanced Blood Pressure Analysis Module
Integrates optimized Random Forest model for high-accuracy BP prediction
Predicts both systolic/diastolic values and BP category
"""

import numpy as np
import pandas as pd
from scipy.signal import butter, filtfilt, find_peaks, welch, savgol_filter
from scipy.stats import skew, kurtosis
import joblib
import logging
from typing import Dict, List, Any, Optional

logger = logging.getLogger(__name__)

def extract_enhanced_features(ppg_segment, fs=125):
    """Enhanced feature extraction for BP regression (compatibility with real data model)"""
    features = {}
    
    # Statistical features
    features['mean'] = np.mean(ppg_segment)
    features['std'] = np.std(ppg_segment)
    features['skewness'] = skew(ppg_segment)
    features['kurtosis'] = kurtosis(ppg_segment)
    features['variance'] = np.var(ppg_segment)
    features['rms'] = np.sqrt(np.mean(ppg_segment**2))
    features['mad'] = np.mean(np.abs(ppg_segment - np.mean(ppg_segment)))
    features['cv'] = np.std(ppg_segment) / (np.mean(ppg_segment) + 1e-8)
    
    # Peak analysis
    peaks, properties = find_peaks(ppg_segment, height=np.mean(ppg_segment), distance=fs*0.6)
    
    if len(peaks) >= 3:
        peak_intervals = np.diff(peaks) / fs
        peak_heights = properties['peak_heights']
        
        features['peak_count'] = len(peaks)
        features['peak_mean_height'] = np.mean(peak_heights)
        features['peak_std_height'] = np.std(peak_heights)
        features['peak_mean_interval'] = np.mean(peak_intervals)
        features['peak_std_interval'] = np.std(peak_intervals)
        features['peak_cv_interval'] = np.std(peak_intervals) / (np.mean(peak_intervals) + 1e-8)
        
        # HRV features
        rr_intervals = np.diff(peaks) / fs * 1000  # Convert to ms
        features['hrv_rmssd'] = np.sqrt(np.mean(np.diff(rr_intervals)**2))
        features['hrv_sdnn'] = np.std(rr_intervals)
        features['hrv_mean'] = np.mean(rr_intervals)
        features['hrv_cv'] = np.std(rr_intervals) / (np.mean(rr_intervals) + 1e-8)
        
        # Heart rate
        hr_values = 60 / peak_intervals
        features['mean_hr'] = np.mean(hr_values)
        features['hr_std'] = np.std(hr_values)
        
    else:
        # Default values when insufficient peaks
        for key in ['peak_count', 'peak_mean_height', 'peak_std_height', 'peak_mean_interval', 
                   'peak_std_interval', 'peak_cv_interval', 'hrv_rmssd', 'hrv_sdnn', 
                   'hrv_mean', 'hrv_cv', 'mean_hr', 'hr_std']:
            features[key] = 0
    
    # Frequency domain features
    freqs, psd = welch(ppg_segment, fs=fs, nperseg=min(len(ppg_segment)//4, 256))
    
    # Frequency bands
    lf_band = (freqs >= 0.04) & (freqs < 0.15)
    hf_band = (freqs >= 0.15) & (freqs < 0.4)
    
    lf_power = np.trapz(psd[lf_band], freqs[lf_band]) if np.any(lf_band) else 0
    hf_power = np.trapz(psd[hf_band], freqs[hf_band]) if np.any(hf_band) else 0
    
    features['freq_lf_power'] = lf_power
    features['freq_hf_power'] = hf_power
    features['freq_lf_hf_ratio'] = lf_power / (hf_power + 1e-8)
    features['freq_peak_frequency'] = freqs[np.argmax(psd)] if len(psd) > 0 else 0
    
    # Spectral entropy
    psd_norm = psd / (np.sum(psd) + 1e-8)
    features['freq_spectral_entropy'] = -np.sum(psd_norm * np.log(psd_norm + 1e-10))
    
    # Morphological features
    if len(ppg_segment) > 5:
        smoothed = savgol_filter(ppg_segment, window_length=5, polyorder=2)
    else:
        smoothed = ppg_segment
    
    first_derivative = np.gradient(smoothed)
    second_derivative = np.gradient(first_derivative)
    
    features['morph_signal_energy'] = np.sum(ppg_segment**2)
    features['morph_first_deriv_mean'] = np.mean(first_derivative)
    features['morph_first_deriv_std'] = np.std(first_derivative)
    features['morph_second_deriv_mean'] = np.mean(second_derivative)
    features['morph_second_deriv_std'] = np.std(second_derivative)
    features['morph_zero_crossings_1st'] = len(np.where(np.diff(np.signbit(first_derivative)))[0])
    features['morph_zero_crossings_2nd'] = len(np.where(np.diff(np.signbit(second_derivative)))[0])
    features['morph_signal_complexity'] = np.std(first_derivative) / (np.std(ppg_segment) + 1e-8)
    
    return features

class OptimizedPPGFeatureExtractor:
    """Optimized feature extraction for BP prediction"""
    
    def __init__(self, sampling_rate=30):
        self.sampling_rate = sampling_rate
        
    def extract_statistical_features(self, ppg_signal):
        """Enhanced statistical features"""
        features = {
            'mean': np.mean(ppg_signal),
            'std': np.std(ppg_signal),
            'min': np.min(ppg_signal),
            'max': np.max(ppg_signal),
            'range': np.max(ppg_signal) - np.min(ppg_signal),
            'median': np.median(ppg_signal),
            'q25': np.percentile(ppg_signal, 25),
            'q75': np.percentile(ppg_signal, 75),
            'iqr': np.percentile(ppg_signal, 75) - np.percentile(ppg_signal, 25),
            'skewness': skew(ppg_signal),
            'kurtosis': kurtosis(ppg_signal),
            'variance': np.var(ppg_signal),
            'rms': np.sqrt(np.mean(ppg_signal**2)),
            'mad': np.mean(np.abs(ppg_signal - np.mean(ppg_signal))),
            'cv': np.std(ppg_signal) / (np.mean(ppg_signal) + 1e-8),
        }
        return features
    
    def extract_peak_features(self, ppg_signal):
        """Enhanced peak analysis"""
        peaks, properties = find_peaks(ppg_signal, height=np.mean(ppg_signal), distance=8)
        
        if len(peaks) < 3:
            return {f'peak_{key}': 0 for key in ['count', 'mean_height', 'std_height', 
                                                'mean_interval', 'std_interval', 'cv_interval',
                                                'prominence_mean', 'amplitude_variation']}
        
        peak_intervals = np.diff(peaks) / self.sampling_rate
        peak_heights = properties['peak_heights']
        
        features = {
            'peak_count': len(peaks),
            'peak_mean_height': np.mean(peak_heights),
            'peak_std_height': np.std(peak_heights),
            'peak_mean_interval': np.mean(peak_intervals),
            'peak_std_interval': np.std(peak_intervals),
            'peak_cv_interval': np.std(peak_intervals) / (np.mean(peak_intervals) + 1e-8),
            'peak_prominence_mean': np.mean(properties.get('prominences', [0])),
            'peak_amplitude_variation': np.std(peak_heights) / (np.mean(peak_heights) + 1e-8),
        }
        
        return features
    
    def extract_hrv_features(self, ppg_signal):
        """Enhanced HRV features"""
        peaks, _ = find_peaks(ppg_signal, height=np.mean(ppg_signal), distance=8)
        
        if len(peaks) < 5:
            return {f'hrv_{key}': 0 for key in ['rmssd', 'sdnn', 'pnn50', 'triangular_index', 
                                              'stress_index', 'baevsky_index']}
        
        rr_intervals = np.diff(peaks) / self.sampling_rate * 1000  # Convert to ms
        
        # Standard HRV features
        rmssd = np.sqrt(np.mean(np.diff(rr_intervals)**2))
        sdnn = np.std(rr_intervals)
        
        # pNN50
        diff_rr = np.abs(np.diff(rr_intervals))
        pnn50 = (np.sum(diff_rr > 50) / len(diff_rr)) * 100 if len(diff_rr) > 0 else 0
        
        # Triangular index
        hist, _ = np.histogram(rr_intervals, bins=20)
        triangular_index = len(rr_intervals) / (np.max(hist) + 1e-8)
        
        # Stress-related indices
        stress_index = 50 / (2 * 0.0648 * np.mean(rr_intervals)) if np.mean(rr_intervals) > 0 else 0
        baevsky_index = np.mean(rr_intervals) / (2 * 0.0648 * np.std(rr_intervals)) if np.std(rr_intervals) > 0 else 0
        
        features = {
            'hrv_rmssd': rmssd,
            'hrv_sdnn': sdnn,
            'hrv_pnn50': pnn50,
            'hrv_triangular_index': triangular_index,
            'hrv_stress_index': stress_index,
            'hrv_baevsky_index': baevsky_index,
        }
        
        return features
    
    def extract_frequency_features(self, ppg_signal):
        """Enhanced frequency domain features"""
        freqs, psd = welch(ppg_signal, fs=self.sampling_rate, nperseg=min(len(ppg_signal)//4, 256))
        
        # Frequency bands
        vlf_band = (freqs >= 0.003) & (freqs < 0.04)
        lf_band = (freqs >= 0.04) & (freqs < 0.15)
        hf_band = (freqs >= 0.15) & (freqs < 0.4)
        
        vlf_power = np.trapz(psd[vlf_band], freqs[vlf_band]) if np.any(vlf_band) else 0
        lf_power = np.trapz(psd[lf_band], freqs[lf_band]) if np.any(lf_band) else 0
        hf_power = np.trapz(psd[hf_band], freqs[hf_band]) if np.any(hf_band) else 0
        total_power = vlf_power + lf_power + hf_power
        
        # Peak frequency and spectral features
        peak_freq = freqs[np.argmax(psd)] if len(psd) > 0 else 0
        spectral_centroid = np.sum(freqs * psd) / (np.sum(psd) + 1e-8)
        
        # Spectral entropy
        psd_norm = psd / (np.sum(psd) + 1e-8)
        spectral_entropy = -np.sum(psd_norm * np.log(psd_norm + 1e-10))
        
        features = {
            'freq_vlf_power': vlf_power,
            'freq_lf_power': lf_power,
            'freq_hf_power': hf_power,
            'freq_total_power': total_power,
            'freq_lf_hf_ratio': lf_power / (hf_power + 1e-8),
            'freq_normalized_lf': lf_power / (total_power + 1e-8),
            'freq_normalized_hf': hf_power / (total_power + 1e-8),
            'freq_peak_frequency': peak_freq,
            'freq_spectral_centroid': spectral_centroid,
            'freq_spectral_entropy': spectral_entropy,
        }
        
        return features
    
    def extract_morphological_features(self, ppg_signal):
        """Morphological features from signal shape"""
        # Smooth signal
        if len(ppg_signal) > 5:
            smoothed = savgol_filter(ppg_signal, window_length=5, polyorder=2)
        else:
            smoothed = ppg_signal
        
        # Derivatives
        first_derivative = np.gradient(smoothed)
        second_derivative = np.gradient(first_derivative)
        
        # Zero crossings
        zero_crossings_1st = len(np.where(np.diff(np.signbit(first_derivative)))[0])
        zero_crossings_2nd = len(np.where(np.diff(np.signbit(second_derivative)))[0])
        
        features = {
            'morph_signal_energy': np.sum(ppg_signal**2),
            'morph_first_deriv_mean': np.mean(first_derivative),
            'morph_first_deriv_std': np.std(first_derivative),
            'morph_second_deriv_mean': np.mean(second_derivative),
            'morph_second_deriv_std': np.std(second_derivative),
            'morph_zero_crossings_1st': zero_crossings_1st,
            'morph_zero_crossings_2nd': zero_crossings_2nd,
            'morph_area_under_curve': np.trapz(np.abs(ppg_signal)),
            'morph_signal_complexity': np.std(first_derivative) / (np.std(ppg_signal) + 1e-8),
            'morph_linearity': np.corrcoef(np.arange(len(ppg_signal)), ppg_signal)[0, 1] if len(ppg_signal) > 1 else 0,
        }
        
        return features
    
    def extract_pulse_wave_features(self, ppg_signal):
        """Simplified pulse wave analysis"""
        peaks, properties = find_peaks(ppg_signal, height=np.mean(ppg_signal), distance=15)
        
        if len(peaks) < 2:
            return {f'pw_{key}': 0 for key in ['pulse_width', 'rising_time', 'falling_time', 'pulse_area']}
        
        features = {}
        pulse_widths = []
        rising_times = []
        falling_times = []
        pulse_areas = []
        
        for i, peak in enumerate(peaks[:-1]):
            start_idx = peaks[i]
            end_idx = peaks[i + 1] if i + 1 < len(peaks) else len(ppg_signal) - 1
            
            if end_idx - start_idx > 10:
                pulse_segment = ppg_signal[start_idx:end_idx]
                pulse_widths.append((end_idx - start_idx) / self.sampling_rate)
                
                mid_point = len(pulse_segment) // 2
                rising_times.append(mid_point / self.sampling_rate)
                falling_times.append((len(pulse_segment) - mid_point) / self.sampling_rate)
                pulse_areas.append(np.trapz(pulse_segment))
        
        features['pw_pulse_width'] = np.mean(pulse_widths) if pulse_widths else 0
        features['pw_rising_time'] = np.mean(rising_times) if rising_times else 0
        features['pw_falling_time'] = np.mean(falling_times) if falling_times else 0
        features['pw_pulse_area'] = np.mean(pulse_areas) if pulse_areas else 0
        
        return features
    
    def extract_all_features(self, ppg_signal):
        """Extract all optimized features"""
        features = {}
        
        if len(ppg_signal) < 10:
            return {f'feature_{i}': 0 for i in range(45)}
        
        # Normalize signal
        ppg_signal = (ppg_signal - np.mean(ppg_signal)) / (np.std(ppg_signal) + 1e-8)
        
        # Extract feature groups
        features.update(self.extract_statistical_features(ppg_signal))
        features.update(self.extract_peak_features(ppg_signal))
        features.update(self.extract_hrv_features(ppg_signal))
        features.update(self.extract_frequency_features(ppg_signal))
        features.update(self.extract_morphological_features(ppg_signal))
        features.update(self.extract_pulse_wave_features(ppg_signal))
        
        return features
    


class BPAnalyzer:
    def __init__(self, model_path: str = "real_ppg_bp_model.joblib"):
        """
        Initialize Enhanced BP Analyzer with real data model
        
        Args:
            model_path: Path to real data trained model (97.9% systolic, 87.5% diastolic accuracy)
        """
        self.model_data = None
        self.models = None
        self.scaler = None
        self.feature_names = None
        self.feature_extractor = None
        self.fs = 30  # Sampling rate (frames per second)
        
        # Load optimized model
        try:
            self.model_data = joblib.load(model_path)
            self.models = self.model_data['models']
            self.scaler = self.model_data['scaler']
            self.feature_names = self.model_data['feature_names']
            self.feature_extractor = OptimizedPPGFeatureExtractor()
            
            logger.info(f"âœ… Real data BP model loaded successfully from {model_path}")
            logger.info(f"ðŸ“Š Model type: XGBoost with 97.9% systolic, 87.5% diastolic accuracy")
            logger.info(f"ðŸŽ¯ Features: {len(self.feature_names)} features")
            
        except Exception as e:
            logger.error(f"âŒ Error loading real data BP model: {str(e)}")
            raise

    def preprocess_ppg_signal(self, ppg_signal: List[float]) -> np.ndarray:
        """
        Preprocess PPG signal for BP prediction
        
        Args:
            ppg_signal: Raw PPG signal data
            
        Returns:
            Preprocessed PPG signal
        """
        try:
            # Convert to numpy array
            signal = np.array(ppg_signal, dtype=float)
            
            # Remove outliers using IQR method
            Q1 = np.percentile(signal, 25)
            Q3 = np.percentile(signal, 75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            signal = np.clip(signal, lower_bound, upper_bound)
            
            # Apply bandpass filter for physiological range
            if len(signal) > 20:
                nyq = 0.5 * self.fs
                low = 0.5 / nyq
                high = 8.0 / nyq
                b, a = butter(4, [low, high], btype='band')
                signal = filtfilt(b, a, signal)
            
            logger.info(f"âœ… Preprocessed PPG signal: {len(signal)} samples")
            return signal
            
        except Exception as e:
            logger.error(f"Error in PPG preprocessing: {str(e)}")
            return np.array(ppg_signal, dtype=float)

    def predict_bp_category(self, ppg_signal: List[float]) -> Dict[str, Any]:
        """
        Predict blood pressure using optimized Random Forest model
        
        Args:
            ppg_signal: Raw PPG signal (30 seconds worth)
            
        Returns:
            BP prediction results with systolic/diastolic values and category
        """
        try:
            if self.models is None:
                return {
                    "systolic_bp": 0,
                    "diastolic_bp": 0,
                    "bp_category": "Unknown",
                    "confidence": 0,
                    "error": "Model not loaded",
                    "status": "error"
                }
            
            # Preprocess the signal
            processed_signal = self.preprocess_ppg_signal(ppg_signal)
            
            # Extract features using optimized feature extractor
            features = self.feature_extractor.extract_all_features(processed_signal)
            
            # Prepare feature vector for prediction
            feature_df = pd.DataFrame([features])
            
            # Ensure all training features are present
            for col in self.feature_names:
                if col not in feature_df.columns:
                    feature_df[col] = 0
            
            # Reorder columns to match training
            feature_df = feature_df[self.feature_names]
            
            # Predict systolic and diastolic BP
            systolic_pred = self.models['systolic'].predict(feature_df)[0]
            diastolic_pred = self.models['diastolic'].predict(feature_df)[0]
            
            # Round to reasonable values
            systolic = round(np.clip(systolic_pred, 90, 190), 1)
            diastolic = round(np.clip(diastolic_pred, 60, 120), 1)
            
            # Categorize BP based on predicted values
            bp_category = self._categorize_bp(systolic, diastolic)
            
            # Calculate confidence based on signal quality
            confidence = self._calculate_confidence(features, len(processed_signal))
            
            result = {
                "systolic_bp": systolic,
                "diastolic_bp": diastolic,
                "bp_category": bp_category,
                "confidence": confidence,
                "signal_length": len(ppg_signal),
                "processed_length": len(processed_signal),
                "features_count": len(features),
                "status": "success"
            }
            
            logger.info(f"ðŸŽ¯ BP Prediction: {systolic}/{diastolic} mmHg, Category: {bp_category} (confidence: {confidence}%)")
            return result
            
        except Exception as e:
            logger.error(f"Error in BP prediction: {str(e)}")
            return {
                "systolic_bp": 0,
                "diastolic_bp": 0,
                "bp_category": "Unknown",
                "confidence": 0,
                "error": str(e),
                "status": "error"
            }

    def _categorize_bp(self, systolic: float, diastolic: float) -> str:
        """Categorize BP based on systolic and diastolic values"""
        if systolic < 120 and diastolic < 80:
            return "Normal"
        elif systolic < 130 and diastolic < 80:
            return "Elevated"
        elif systolic < 140 or diastolic < 90:
            return "High Blood Pressure Stage 1"
        elif systolic >= 140 or diastolic >= 90:
            return "High Blood Pressure Stage 2"
        else:
            return "Hypertensive Crisis"

    def _calculate_confidence(self, features: Dict, signal_length: int) -> int:
        """Calculate prediction confidence based on signal quality and features"""
        confidence = 70  # Base confidence
        
        # Signal length quality
        if signal_length >= 600:  # 20 seconds of data at 30fps
            confidence += 10
        
        # Peak detection quality
        if 'peak_count' in features and features['peak_count'] > 25:
            confidence += 8
        
        # HRV quality indicators
        if 'hrv_sdnn' in features and features['hrv_sdnn'] > 10:
            confidence += 6
        
        # Frequency domain quality
        if 'freq_spectral_entropy' in features and features['freq_spectral_entropy'] > 1.5:
            confidence += 4
        
        # Signal complexity
        if 'morph_signal_complexity' in features and 0.5 < features['morph_signal_complexity'] < 2.0:
            confidence += 4
        
        return min(95, confidence)

    def get_bp_interpretation(self, bp_category: str, systolic: float, diastolic: float) -> Dict[str, str]:
        """
        Get interpretation and recommendations for BP reading
        
        Args:
            bp_category: Predicted BP category
            systolic: Systolic BP value
            diastolic: Diastolic BP value
            
        Returns:
            Interpretation and recommendations
        """
        interpretations = {
            "Normal": {
                "interpretation": "Normal Blood Pressure",
                "description": f"Your blood pressure ({systolic}/{diastolic} mmHg) is in the normal range",
                "recommendation": "Maintain healthy lifestyle habits including regular exercise and balanced diet",
                "risk_level": "Low"
            },
            "Elevated": {
                "interpretation": "Elevated Blood Pressure", 
                "description": f"Your blood pressure ({systolic}/{diastolic} mmHg) is elevated but not yet hypertensive",
                "recommendation": "Consider lifestyle modifications and regular monitoring. Consult healthcare provider",
                "risk_level": "Moderate"
            },
            "High Blood Pressure Stage 1": {
                "interpretation": "High Blood Pressure Stage 1",
                "description": f"Your blood pressure ({systolic}/{diastolic} mmHg) indicates Stage 1 hypertension",
                "recommendation": "Consult healthcare provider for proper evaluation and treatment plan",
                "risk_level": "High"
            },
            "High Blood Pressure Stage 2": {
                "interpretation": "High Blood Pressure Stage 2",
                "description": f"Your blood pressure ({systolic}/{diastolic} mmHg) indicates Stage 2 hypertension",
                "recommendation": "Seek immediate medical attention for proper evaluation and treatment",
                "risk_level": "Very High"
            },
            "Hypertensive Crisis": {
                "interpretation": "Hypertensive Crisis",
                "description": f"Your blood pressure ({systolic}/{diastolic} mmHg) is extremely high",
                "recommendation": "Seek emergency medical attention immediately",
                "risk_level": "Critical"
            }
        }
        
        return interpretations.get(bp_category, {
            "interpretation": "Unknown",
            "description": f"Unable to determine blood pressure category for {systolic}/{diastolic} mmHg",
            "recommendation": "Please try again or consult healthcare provider",
            "risk_level": "Unknown"
        })
